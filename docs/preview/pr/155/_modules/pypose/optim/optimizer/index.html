


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pypose.optim.optimizer &mdash; PyPose main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/katex-math.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex/" />
    <link rel="search" title="Search" href="../../../../search/" />

<!--
  Search engines should not index the master version of documentation.
  Stable documentation are built without release == 'main'.
-->
<meta name="robots" content="noindex">


  <!-- Google Analytics -->
  
  <!-- End Google Analytics -->
  


  
  <script src="../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pypose.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pypose.org/get-started">Get Started</a>
          </li>

          <!-- <li> -->
          <li>
            <a href="https://pypose.org/tutorials">Tutorials</a>
          </li>

          <!-- <li class="active docs-active"> -->
          <li>
            <a href="https://pypose.org/docs/main/index.html">Doc</a>
          </li>

          <li>
            <a href="https://pypose.org/about-us">About Us</a>
          </li>

          <li>
            <a href="https://github.com/pypose/pypose">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pypose.org/docs/versions.html'>0.2.2 &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search/" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          

<div>
  <a style="color:#F05732" href="_modules/pypose/optim/optimizer.html">
    You are viewing unstable developer preview docs.
    Click here to view docs for latest stable release.
  </a>
</div>


            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../lietensor/">LieTensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../basics/">Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../convert/">Convert</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules/">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim/">Optimization</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../">Module code</a> &gt;</li>
        
      <li>pypose.optim.optimizer</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for pypose.optim.optimizer</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">torch</span><span class="o">,</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">..basics</span> <span class="kn">import</span> <span class="n">bmv</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">finfo</span>
<span class="kn">from</span> <span class="nn">.functional</span> <span class="kn">import</span> <span class="n">modjac</span>
<span class="kn">from</span> <span class="nn">.strategy</span> <span class="kn">import</span> <span class="n">TrustRegion</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Optimizer</span>
<span class="kn">from</span> <span class="nn">.solver</span> <span class="kn">import</span> <span class="n">PINV</span><span class="p">,</span> <span class="n">Cholesky</span>
<span class="kn">from</span> <span class="nn">torch.linalg</span> <span class="kn">import</span> <span class="n">cholesky_ex</span>


<span class="k">class</span> <span class="nc">Trivial</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A trivial module. Get anything, return anything.</span>
<span class="sd">    Not supposed to be called by PyPose users.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">*</span><span class="n">kwargs</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">out</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">out</span>


<span class="k">class</span> <span class="nc">RobustModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Standardize a model for least square problems with an option of square-rooting kernel.</span>
<span class="sd">    Then model regression becomes minimizing the output of the standardized model.</span>
<span class="sd">    This class is used during optimization but is not designed to expose to PyPose users.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">auto</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">Trivial</span><span class="p">()</span> <span class="k">if</span> <span class="n">kernel</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">kernel</span>

        <span class="k">if</span> <span class="n">auto</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_forward_hook</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_forward</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">residual</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">model_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">residual</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">output</span> <span class="k">if</span> <span class="n">target</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">output</span> <span class="o">-</span> <span class="n">target</span>

    <span class="k">def</span> <span class="nf">kernel_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
        <span class="c1"># eps is to prevent grad of sqrt() from being inf</span>
        <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_floating_point</span><span class="p">(</span><span class="n">output</span><span class="p">),</span> <span class="s2">&quot;model output have to be float type.&quot;</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">finfo</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">square</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="n">eps</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="n">residual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">residual</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">residual</span><span class="o">.</span><span class="n">square</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">_Optimizer</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Base class for all second order optimizers.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">update_parameter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        params will be updated by calling this function</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">steps</span> <span class="o">=</span> <span class="n">step</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">params</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">])</span>
        <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">steps</span><span class="p">)</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span>


<div class="viewcode-block" id="GaussNewton"><a class="viewcode-back" href="../../../../generated/pypose.optim.GaussNewton/#pypose.optim.GaussNewton">[docs]</a><span class="k">class</span> <span class="nc">GaussNewton</span><span class="p">(</span><span class="n">_Optimizer</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    The Gauss-Newton (GN) algorithm solving non-linear least squares problems. This implementation</span>
<span class="sd">    is for optimizing the model parameters to approximate the target, which can be a</span>
<span class="sd">    Tensor/LieTensor or a tuple of Tensors/LieTensors.</span>

<span class="sd">    .. math::</span>
<span class="sd">        \bm{\theta}^* = \arg\min_{\bm{\theta}} \sum_i </span>
<span class="sd">            \rho\left((\bm{f}(\bm{\theta},\bm{x}_i)-\bm{y}_i)^T \mathbf{W}_i</span>
<span class="sd">            (\bm{f}(\bm{\theta},\bm{x}_i)-\bm{y}_i)\right),</span>

<span class="sd">    where :math:`\bm{f}()` is the model, :math:`\bm{\theta}` is the parameters to be optimized,</span>
<span class="sd">    :math:`\bm{x}` is the model input, :math:`\mathbf{W}_i` is a weighted square matrix (positive</span>
<span class="sd">    definite), and :math:`\rho` is a robust kernel function to reduce the effect of outliers.</span>
<span class="sd">    :math:`\rho(x) = x` is used by default.</span>

<span class="sd">    .. math::</span>
<span class="sd">       \begin{aligned}</span>
<span class="sd">            &amp;\rule{113mm}{0.4pt}                                                                 \\</span>
<span class="sd">            &amp;\textbf{input}: \bm{\theta}_0~\text{(params)}, \bm{f}~\text{(model)},</span>
<span class="sd">                \bm{x}~(\text{input}), \bm{y}~(\text{target}), \rho~(\text{kernel})              \\</span>
<span class="sd">            &amp;\rule{113mm}{0.4pt}                                                                 \\</span>
<span class="sd">            &amp;\textbf{for} \: t=1 \: \textbf{to} \: \ldots \: \textbf{do}                         \\</span>
<span class="sd">            &amp;\hspace{5mm} \mathbf{J} \leftarrow {\dfrac {\partial \bm{f} } {\partial \bm{\theta}_{t-1}}}             \\</span>
<span class="sd">            &amp;\hspace{5mm} \mathbf{R} = \bm{f(\bm{\theta}_{t-1}, \bm{x})}-\bm{y}                  \\</span>
<span class="sd">            &amp;\hspace{5mm} \mathbf{R}, \mathbf{J}=\mathrm{corrector}(\rho, \mathbf{R}, \mathbf{J})\\</span>
<span class="sd">            &amp;\hspace{5mm} \bm{\delta} = \mathrm{solver}(\mathbf{W}\mathbf{J}, -\mathbf{W}\mathbf{R})                 \\</span>
<span class="sd">            &amp;\hspace{5mm} \bm{\theta}_t \leftarrow \bm{\theta}_{t-1} + \bm{\delta}               \\</span>
<span class="sd">            &amp;\rule{113mm}{0.4pt}                                                          \\[-1.ex]</span>
<span class="sd">            &amp;\bf{return} \:  \theta_t                                                     \\[-1.ex]</span>
<span class="sd">            &amp;\rule{113mm}{0.4pt}                                                          \\[-1.ex]</span>
<span class="sd">       \end{aligned}</span>

<span class="sd">    Args:</span>
<span class="sd">        model (nn.Module): a module containing learnable parameters.</span>
<span class="sd">        solver (nn.Module, optional): a linear solver. Available linear solvers include</span>
<span class="sd">            :meth:`solver.PINV` and :meth:`solver.LSTSQ`. If ``None``, :meth:`solver.PINV` is used.</span>
<span class="sd">            Default: ``None``.</span>
<span class="sd">        kernel (nn.Module, optional): a robust kernel function. Default: ``None``.</span>
<span class="sd">        corrector: (nn.Module, optional): a Jacobian and model residual corrector to fit</span>
<span class="sd">            the kernel function. If a kernel is given but a corrector is not specified, auto</span>
<span class="sd">            correction is used. Auto correction can be unstable when the robust model has</span>
<span class="sd">            indefinite Hessian. Default: ``None``.</span>
<span class="sd">        weight (Tensor, optional): a square positive definite matrix defining the weight of</span>
<span class="sd">            model residual. Use this only when all inputs shared the same weight matrices. This is</span>
<span class="sd">            ignored when weight is given when calling :meth:`.step` or :meth:`.optimize` method.</span>
<span class="sd">            Default: ``None``.</span>
<span class="sd">        vectorize (bool, optional): the method of computing Jacobian. If ``True``, the</span>
<span class="sd">            gradient of each scalar in output with respect to the model parameters will be</span>
<span class="sd">            computed in parallel with ``&quot;reverse-mode&quot;``. More details go to</span>
<span class="sd">            :meth:`pypose.optim.functional.modjac`. Default: ``True``.</span>

<span class="sd">    Available solvers: :meth:`solver.PINV`; :meth:`solver.LSTSQ`.</span>

<span class="sd">    Available kernels: :meth:`kernel.Huber`; :meth:`kernel.PseudoHuber`; :meth:`kernel.Cauchy`.</span>

<span class="sd">    Available correctors: :meth:`corrector.FastTriggs`; :meth:`corrector.Triggs`.</span>

<span class="sd">    Warning:</span>
<span class="sd">        The output of model :math:`\bm{f}(\bm{\theta},\bm{x}_i)` and target :math:`\bm{y}_i`</span>
<span class="sd">        can be any shape, while their **last dimension** :math:`d` is always taken as the</span>
<span class="sd">        dimension of model residual, whose inner product is the input to the kernel function.</span>
<span class="sd">        This is useful for residuals like re-projection error, whose last dimension is 2.</span>

<span class="sd">        Note that **auto correction** is equivalent to the method of &#39;square-rooting the kernel&#39;</span>
<span class="sd">        mentioned in Section 3.3 of the following paper. It replaces the</span>
<span class="sd">        :math:`d`-dimensional residual with a one-dimensional one, which loses</span>
<span class="sd">        residual-level structural information.</span>

<span class="sd">        * Christopher Zach, `Robust Bundle Adjustment Revisited</span>
<span class="sd">          &lt;https://link.springer.com/chapter/10.1007/978-3-319-10602-1_50&gt;`_, European</span>
<span class="sd">          Conference on Computer Vision (ECCV), 2014.</span>

<span class="sd">        **Therefore, the users need to keep the last dimension of model output and target to</span>
<span class="sd">        1, even if the model residual is a scalar. If the users flatten all sample residuals </span>
<span class="sd">        into a vector (residual inner product will be a scalar), the model Jacobian will be a</span>
<span class="sd">        row vector, instead of a matrix, which loses sample-level structural information,</span>
<span class="sd">        although computing Jacobian vector is faster.**</span>

<span class="sd">    Note:</span>
<span class="sd">        Instead of solving :math:`\mathbf{J}^T\mathbf{J}\delta = -\mathbf{J}^T\mathbf{R}`, we solve</span>
<span class="sd">        :math:`\mathbf{J}\delta = -\mathbf{R}` via pseudo inversion, which is more numerically</span>
<span class="sd">        advisable. Therefore, only solvers with pseudo inversion (inverting non-square matrices)</span>
<span class="sd">        such as :meth:`solver.PINV` and :meth:`solver.LSTSQ` are available.</span>
<span class="sd">        More details are in Eq. (5) of the paper &quot;`Robust Bundle Adjustment Revisited`_&quot;.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">corrector</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">defaults</span><span class="o">=</span><span class="p">{})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">=</span> <span class="n">PINV</span><span class="p">()</span> <span class="k">if</span> <span class="n">solver</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">solver</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">jackwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;vectorize&#39;</span><span class="p">:</span> <span class="n">vectorize</span><span class="p">,</span> <span class="s1">&#39;flatten&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">kernel</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">corrector</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># auto diff of robust model will be computed</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">RobustModel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">auto</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">corrector</span> <span class="o">=</span> <span class="n">Trivial</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># manually Jacobian correction will be computed</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">RobustModel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">auto</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">corrector</span> <span class="o">=</span> <span class="n">Trivial</span><span class="p">()</span> <span class="k">if</span> <span class="n">corrector</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">corrector</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span>

<div class="viewcode-block" id="GaussNewton.step"><a class="viewcode-back" href="../../../../generated/pypose.optim.GaussNewton/#pypose.optim.GaussNewton.step">[docs]</a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Performs a single optimization step.</span>

<span class="sd">        Args:</span>
<span class="sd">            input (Tensor/LieTensor or tuple of Tensors/LieTensors): the input to the model.</span>
<span class="sd">            target (Tensor/LieTensor): the model target to approximate.</span>
<span class="sd">                If not given, the model output is minimized. Default: ``None``.</span>
<span class="sd">            weight (Tensor, optional): a square positive definite matrix defining the weight of</span>
<span class="sd">                model residual. Default: ``None``.</span>

<span class="sd">        Return:</span>
<span class="sd">            Tensor: the minimized model loss.</span>

<span class="sd">        Note:</span>
<span class="sd">            Different from PyTorch optimizers like</span>
<span class="sd">            `SGD &lt;https://pytorch.org/docs/stable/generated/torch.optim.SGD.html&gt;`_, where the model</span>
<span class="sd">            error has to be a scalar, the output of model :math:`\bm{f}` can be a Tensor/LieTensor or a</span>
<span class="sd">            tuple of Tensors/LieTensors.</span>

<span class="sd">            See more details of</span>
<span class="sd">            `Gauss-Newton (GN) algorithm &lt;https://en.wikipedia.org/wiki/Gauss-Newton_algorithm&gt;`_ on</span>
<span class="sd">            Wikipedia.</span>

<span class="sd">        Example:</span>
<span class="sd">            Optimizing a simple module to **approximate pose inversion**.</span>

<span class="sd">            &gt;&gt;&gt; class PoseInv(nn.Module):</span>
<span class="sd">            ...     def __init__(self, *dim):</span>
<span class="sd">            ...         super().__init__()</span>
<span class="sd">            ...         self.pose = pp.Parameter(pp.randn_se3(*dim))</span>
<span class="sd">            ...</span>
<span class="sd">            ...     def forward(self, input):</span>
<span class="sd">            ...         # the last dimension of the output is 6,</span>
<span class="sd">            ...         # which will be the residual dimension.</span>
<span class="sd">            ...         return (self.pose.Exp() @ input).Log()</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; posinv = PoseInv(2, 2)</span>
<span class="sd">            &gt;&gt;&gt; input = pp.randn_SE3(2, 2)</span>
<span class="sd">            &gt;&gt;&gt; optimizer = pp.optim.GN(posinv)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; for idx in range(10):</span>
<span class="sd">            ...     error = optimizer.step(input)</span>
<span class="sd">            ...     print(&#39;Pose Inversion error %.7f @ %d it&#39;%(error, idx))</span>
<span class="sd">            ...     if error &lt; 1e-5:</span>
<span class="sd">            ...         print(&#39;Early Stopping with error:&#39;, error.item())</span>
<span class="sd">            ...         break</span>
<span class="sd">            ...</span>
<span class="sd">            Pose Inversion error: 1.6865690 @ 0 it</span>
<span class="sd">            Pose Inversion error: 0.1065131 @ 1 it</span>
<span class="sd">            Pose Inversion error: 0.0002673 @ 2 it</span>
<span class="sd">            Pose Inversion error: 0.0000005 @ 3 it</span>
<span class="sd">            Early Stopping with error: 5.21540641784668e-07</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">for</span> <span class="n">pg</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="k">if</span> <span class="n">weight</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">weight</span>
            <span class="n">R</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
            <span class="n">J</span> <span class="o">=</span> <span class="n">modjac</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">),</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">jackwargs</span><span class="p">)</span>
            <span class="n">R</span><span class="p">,</span> <span class="n">J</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">corrector</span><span class="p">(</span><span class="n">R</span> <span class="o">=</span> <span class="n">R</span><span class="p">,</span> <span class="n">J</span> <span class="o">=</span> <span class="n">J</span><span class="p">)</span>
            <span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">J</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">R</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">R</span>
            <span class="k">if</span> <span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="p">(</span><span class="n">weight</span> <span class="o">@</span> <span class="n">A</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="n">weight</span> <span class="o">@</span> <span class="n">b</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">D</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">(</span><span class="n">A</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="o">-</span><span class="n">b</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">last</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;loss&#39;</span><span class="p">)</span> \
                        <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_parameter</span><span class="p">(</span><span class="n">params</span> <span class="o">=</span> <span class="n">pg</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">],</span> <span class="n">step</span> <span class="o">=</span> <span class="n">D</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span></div></div>


<div class="viewcode-block" id="LevenbergMarquardt"><a class="viewcode-back" href="../../../../generated/pypose.optim.LevenbergMarquardt/#pypose.optim.LevenbergMarquardt">[docs]</a><span class="k">class</span> <span class="nc">LevenbergMarquardt</span><span class="p">(</span><span class="n">_Optimizer</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    The Levenberg-Marquardt (LM) algorithm solving non-linear least squares problems. It</span>
<span class="sd">    is also known as the damped least squares (DLS) method. This implementation is for</span>
<span class="sd">    optimizing the model parameters to approximate the target, which can be a</span>
<span class="sd">    Tensor/LieTensor or a tuple of Tensors/LieTensors.</span>

<span class="sd">    .. math::</span>
<span class="sd">        \bm{\theta}^* = \arg\min_{\bm{\theta}} \sum_i </span>
<span class="sd">            \rho\left((\bm{f}(\bm{\theta},\bm{x}_i)-\bm{y}_i)^T \mathbf{W}_i</span>
<span class="sd">            (\bm{f}(\bm{\theta},\bm{x}_i)-\bm{y}_i)\right),</span>

<span class="sd">    where :math:`\bm{f}()` is the model, :math:`\bm{\theta}` is the parameters to be optimized,</span>
<span class="sd">    :math:`\bm{x}` is the model input, :math:`\mathbf{W}_i` is a weighted square matrix (positive</span>
<span class="sd">    definite), and :math:`\rho` is a robust kernel function to reduce the effect of outliers.</span>
<span class="sd">    :math:`\rho(x) = x` is used by default.</span>

<span class="sd">    .. math::</span>
<span class="sd">       \begin{aligned}</span>
<span class="sd">            &amp;\rule{113mm}{0.4pt}                                                                 \\</span>
<span class="sd">            &amp;\textbf{input}: \lambda~\text{(damping)}, \bm{\theta}_0~\text{(params)},</span>
<span class="sd">                \bm{f}~\text{(model)}, \bm{x}~(\text{input}), \bm{y}~(\text{target})             \\</span>
<span class="sd">            &amp;\hspace{12mm} \rho~(\text{kernel}), \epsilon_{s}~(\text{min}),</span>
<span class="sd">                           \epsilon_{l}~(\text{max})                                             \\</span>
<span class="sd">            &amp;\rule{113mm}{0.4pt}                                                                 \\</span>
<span class="sd">            &amp;\textbf{for} \: t=1 \: \textbf{to} \: \ldots \: \textbf{do}                         \\</span>
<span class="sd">            &amp;\hspace{5mm} \mathbf{J} \leftarrow {\dfrac {\partial \bm{f}} {\partial \bm{\theta}_{t-1}}}       \\</span>
<span class="sd">            &amp;\hspace{5mm} \mathbf{A} \leftarrow (\mathbf{J}^T \mathbf{W} \mathbf{J})</span>
<span class="sd">                                     .\mathrm{diagnal\_clamp(\epsilon_{s}, \epsilon_{l})}        \\</span>
<span class="sd">            &amp;\hspace{5mm} \mathbf{R} = \bm{f(\bm{\theta}_{t-1}, \bm{x})}-\bm{y}                               \\</span>
<span class="sd">            &amp;\hspace{5mm} \mathbf{R}, \mathbf{J}=\mathrm{corrector}(\rho, \mathbf{R}, \mathbf{J})\\</span>
<span class="sd">            &amp;\hspace{5mm} \textbf{while}~\text{first iteration}~\textbf{or}~</span>
<span class="sd">                                         \text{loss not decreasing}                              \\</span>
<span class="sd">            &amp;\hspace{10mm} \mathbf{A} \leftarrow \mathbf{A} + \lambda \mathrm{diag}(\mathbf{A})  \\</span>
<span class="sd">            &amp;\hspace{10mm} \bm{\delta} = \mathrm{solver}(\mathbf{A}, -\mathbf{J}^T \mathbf{W} \mathbf{R})     \\</span>
<span class="sd">            &amp;\hspace{10mm} \lambda \leftarrow \mathrm{strategy}(\lambda,\text{model information})\\</span>
<span class="sd">            &amp;\hspace{10mm} \bm{\theta}_t \leftarrow \bm{\theta}_{t-1} + \bm{\delta}              \\</span>
<span class="sd">            &amp;\hspace{10mm} \textbf{if}~\text{loss not decreasing}~\textbf{and}~</span>
<span class="sd">                                       \text{maximum reject step not reached}                    \\</span>
<span class="sd">            &amp;\hspace{15mm} \bm{\theta}_t \leftarrow \bm{\theta}_{t-1} - \bm{\delta}</span>
<span class="sd">                                                               ~(\text{reject step})             \\</span>
<span class="sd">            &amp;\rule{113mm}{0.4pt}                                                          \\[-1.ex]</span>
<span class="sd">            &amp;\bf{return} \:  \theta_t                                                     \\[-1.ex]</span>
<span class="sd">            &amp;\rule{113mm}{0.4pt}                                                          \\[-1.ex]</span>
<span class="sd">       \end{aligned}</span>

<span class="sd">    Args:</span>
<span class="sd">        model (nn.Module): a module containing learnable parameters.</span>
<span class="sd">        solver (nn.Module, optional): a linear solver. If ``None``, :meth:`solver.Cholesky` is used.</span>
<span class="sd">            Default: ``None``.</span>
<span class="sd">        strategy (object, optional): strategy for adjusting the damping factor. If ``None``, the</span>
<span class="sd">            :meth:`strategy.TrustRegion` will be used. Defult: ``None``.</span>
<span class="sd">        kernel (nn.Module, optional): a robust kernel function. Default: ``None``.</span>
<span class="sd">        corrector: (nn.Module, optional): a Jacobian and model residual corrector to fit the kernel</span>
<span class="sd">            function. If a kernel is given but a corrector is not specified, auto correction is</span>
<span class="sd">            used. Auto correction can be unstable when the robust model has indefinite Hessian.</span>
<span class="sd">            Default: ``None``.</span>
<span class="sd">        weight (Tensor, optional): a square positive definite matrix defining the weight of</span>
<span class="sd">            model residual. Use this only when all inputs shared the same weight matrices. This is</span>
<span class="sd">            ignored when weight is given when calling :meth:`.step` or :meth:`.optimize` method.</span>
<span class="sd">            Default: ``None``.</span>
<span class="sd">        reject (integer, optional): the maximum number of rejecting unsuccessfull steps.</span>
<span class="sd">            Default: 16.</span>
<span class="sd">        min (float, optional): the lower-bound of the Hessian diagonal. Default: 1e-6.</span>
<span class="sd">        max (float, optional): the upper-bound of the Hessian diagonal. Default: 1e32.</span>
<span class="sd">        vectorize (bool, optional): the method of computing Jacobian. If ``True``, the</span>
<span class="sd">            gradient of each scalar in output with respect to the model parameters will be</span>
<span class="sd">            computed in parallel with ``&quot;reverse-mode&quot;``. More details go to</span>
<span class="sd">            :meth:`pypose.optim.functional.modjac`. Default: ``True``.</span>

<span class="sd">    Available solvers: :meth:`solver.PINV`; :meth:`solver.LSTSQ`, :meth:`solver.Cholesky`.</span>

<span class="sd">    Available kernels: :meth:`kernel.Huber`; :meth:`kernel.PseudoHuber`; :meth:`kernel.Cauchy`.</span>

<span class="sd">    Available correctors: :meth:`corrector.FastTriggs`, :meth:`corrector.Triggs`.</span>

<span class="sd">    Available strategies: :meth:`strategy.Constant`; :meth:`strategy.Adaptive`;</span>
<span class="sd">    :meth:`strategy.TrustRegion`;</span>

<span class="sd">    Warning:</span>
<span class="sd">        The output of model :math:`\bm{f}(\bm{\theta},\bm{x}_i)` and target :math:`\bm{y}_i`</span>
<span class="sd">        can be any shape, while their **last dimension** :math:`d` is always taken as the</span>
<span class="sd">        dimension of model residual, whose inner product will be input to the kernel</span>
<span class="sd">        function. This is useful for residuals like re-projection error, whose last</span>
<span class="sd">        dimension is 2.</span>

<span class="sd">        Note that **auto correction** is equivalent to the method of &#39;square-rooting the kernel&#39;</span>
<span class="sd">        mentioned in Section 3.3 of the following paper. It replaces the</span>
<span class="sd">        :math:`d`-dimensional residual with a one-dimensional one, which loses</span>
<span class="sd">        residual-level structural information.</span>

<span class="sd">        * Christopher Zach, `Robust Bundle Adjustment Revisited</span>
<span class="sd">          &lt;https://link.springer.com/chapter/10.1007/978-3-319-10602-1_50&gt;`_, European</span>
<span class="sd">          Conference on Computer Vision (ECCV), 2014.</span>

<span class="sd">        **Therefore, the users need to keep the last dimension of model output and target to</span>
<span class="sd">        1, even if the model residual is a scalar. If the model output only has one dimension,</span>
<span class="sd">        the model Jacobian will be a row vector, instead of a matrix, which loses sample-level</span>
<span class="sd">        structural information, although computing Jacobian vector is faster.**</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">corrector</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> \
                       <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reject</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1e32</span><span class="p">,</span> <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">min</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;min value has to be positive: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">min</span><span class="p">))</span>
        <span class="k">assert</span> <span class="nb">max</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;max value has to be positive: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">max</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span> <span class="o">=</span> <span class="n">TrustRegion</span><span class="p">()</span> <span class="k">if</span> <span class="n">strategy</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">strategy</span>
        <span class="n">defaults</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;min&#39;</span><span class="p">:</span><span class="nb">min</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span><span class="nb">max</span><span class="p">},</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">defaults</span><span class="p">}</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">defaults</span><span class="o">=</span><span class="n">defaults</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">jackwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;vectorize&#39;</span><span class="p">:</span> <span class="n">vectorize</span><span class="p">,</span> <span class="s1">&#39;flatten&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">=</span> <span class="n">Cholesky</span><span class="p">()</span> <span class="k">if</span> <span class="n">solver</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">solver</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reject</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reject_count</span> <span class="o">=</span> <span class="n">reject</span><span class="p">,</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">kernel</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">corrector</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># auto diff of robust model will be computed</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">RobustModel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">auto</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">corrector</span> <span class="o">=</span> <span class="n">Trivial</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># manually Jacobian correction will be computed</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">RobustModel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">auto</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">corrector</span> <span class="o">=</span> <span class="n">Trivial</span><span class="p">()</span> <span class="k">if</span> <span class="n">corrector</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">corrector</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span>

<div class="viewcode-block" id="LevenbergMarquardt.step"><a class="viewcode-back" href="../../../../generated/pypose.optim.LevenbergMarquardt/#pypose.optim.LevenbergMarquardt.step">[docs]</a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Performs a single optimization step.</span>

<span class="sd">        Args:</span>
<span class="sd">            input (Tensor/LieTensor or tuple of Tensors/LieTensors): the input to the model.</span>
<span class="sd">            target (Tensor/LieTensor): the model target to optimize.</span>
<span class="sd">                If not given, the squared model output is minimized. Defaults: ``None``.</span>
<span class="sd">            weight (Tensor, optional): a square positive definite matrix defining the weight of</span>
<span class="sd">                model residual. Default: ``None``.</span>

<span class="sd">        Return:</span>
<span class="sd">            Tensor: the minimized model loss.</span>

<span class="sd">        Note:</span>
<span class="sd">            The (non-negative) damping factor :math:`\lambda` can be adjusted at each iteration.</span>
<span class="sd">            If the residual reduces rapidly, a smaller value can be used, bringing the algorithm</span>
<span class="sd">            closer to the Gauss-Newton algorithm, whereas if an iteration gives insufficient</span>
<span class="sd">            residual reduction, :math:`\lambda` can be increased, giving a step closer to the</span>
<span class="sd">            gradient descent direction.</span>

<span class="sd">            See more details of `Levenberg-Marquardt (LM) algorithm</span>
<span class="sd">            &lt;https://en.wikipedia.org/wiki/Levenberg-Marquardt_algorithm&gt;`_ on Wikipedia.</span>

<span class="sd">        Note:</span>
<span class="sd">            Different from PyTorch optimizers like</span>
<span class="sd">            `SGD &lt;https://pytorch.org/docs/stable/generated/torch.optim.SGD.html&gt;`_, where the</span>
<span class="sd">            model error has to be a scalar, the output of model :math:`\bm{f}` can be a</span>
<span class="sd">            Tensor/LieTensor or a tuple of Tensors/LieTensors.</span>

<span class="sd">        Example:</span>
<span class="sd">            Optimizing a simple module to **approximate pose inversion**.</span>

<span class="sd">            &gt;&gt;&gt; class PoseInv(nn.Module):</span>
<span class="sd">            ...     def __init__(self, *dim):</span>
<span class="sd">            ...         super().__init__()</span>
<span class="sd">            ...         self.pose = pp.Parameter(pp.randn_se3(*dim))</span>
<span class="sd">            ...</span>
<span class="sd">            ...     def forward(self, input):</span>
<span class="sd">            ...         # the last dimension of the output is 6,</span>
<span class="sd">            ...         # which will be the residual dimension.</span>
<span class="sd">            ...         return (self.pose.Exp() @ input).Log()</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; posinv = PoseInv(2, 2)</span>
<span class="sd">            &gt;&gt;&gt; input = pp.randn_SE3(2, 2)</span>
<span class="sd">            &gt;&gt;&gt; optimizer = pp.optim.LM(posinv, damping=1e-6)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; for idx in range(10):</span>
<span class="sd">            ...     loss = optimizer.step(input)</span>
<span class="sd">            ...     print(&#39;Pose Inversion loss %.7f @ %d it&#39;%(loss, idx))</span>
<span class="sd">            ...     if loss &lt; 1e-5:</span>
<span class="sd">            ...         print(&#39;Early Stopping with loss:&#39;, loss.item())</span>
<span class="sd">            ...         break</span>
<span class="sd">            ...</span>
<span class="sd">            Pose Inversion error: 1.6600330 @ 0 it</span>
<span class="sd">            Pose Inversion error: 0.1296970 @ 1 it</span>
<span class="sd">            Pose Inversion error: 0.0008593 @ 2 it</span>
<span class="sd">            Pose Inversion error: 0.0000004 @ 3 it</span>
<span class="sd">            Early Stopping with error: 4.443569991963159e-07</span>

<span class="sd">        Note:</span>
<span class="sd">            More practical examples, e.g., pose graph optimization (PGO), can be found at</span>
<span class="sd">            `examples/module/pgo</span>
<span class="sd">            &lt;https://github.com/pypose/pypose/tree/main/examples/module/pgo&gt;`_.    </span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">for</span> <span class="n">pg</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="k">if</span> <span class="n">weight</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">weight</span>
            <span class="n">R</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
            <span class="n">J</span> <span class="o">=</span> <span class="n">modjac</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">),</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">jackwargs</span><span class="p">)</span>
            <span class="n">R</span><span class="p">,</span> <span class="n">J</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">corrector</span><span class="p">(</span><span class="n">R</span> <span class="o">=</span> <span class="n">R</span><span class="p">,</span> <span class="n">J</span> <span class="o">=</span> <span class="n">J</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">last</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;loss&#39;</span><span class="p">)</span> \
                                    <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
            <span class="n">J_T</span> <span class="o">=</span> <span class="n">J</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">R</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">J_T</span> <span class="o">=</span> <span class="p">(</span><span class="n">J_T</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">@</span> <span class="n">weight</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">J_T</span> <span class="o">=</span> <span class="n">J_T</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">J_T</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">A</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reject_count</span> <span class="o">=</span> <span class="n">J_T</span> <span class="o">@</span> <span class="n">J</span><span class="p">,</span> <span class="mi">0</span>
            <span class="n">A</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="n">pg</span><span class="p">[</span><span class="s1">&#39;min&#39;</span><span class="p">],</span> <span class="n">pg</span><span class="p">[</span><span class="s1">&#39;max&#39;</span><span class="p">])</span>
            <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">last</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">:</span>
                <span class="n">A</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span> <span class="o">*</span> <span class="n">pg</span><span class="p">[</span><span class="s1">&#39;damping&#39;</span><span class="p">])</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">D</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">(</span><span class="n">A</span> <span class="o">=</span> <span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="o">-</span><span class="n">J_T</span> <span class="o">@</span> <span class="n">R</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Linear solver failed. Breaking optimization step...&quot;</span><span class="p">)</span>
                    <span class="k">break</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update_parameter</span><span class="p">(</span><span class="n">pg</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">],</span> <span class="n">D</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">pg</span><span class="p">,</span> <span class="n">last</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">last</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">J</span><span class="o">=</span><span class="n">J</span><span class="p">,</span> <span class="n">D</span><span class="o">=</span><span class="n">D</span><span class="p">,</span> <span class="n">R</span><span class="o">=</span><span class="n">R</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">last</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">reject_count</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">reject</span><span class="p">:</span> <span class="c1"># reject step</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">update_parameter</span><span class="p">(</span><span class="n">params</span> <span class="o">=</span> <span class="n">pg</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">],</span> <span class="n">step</span> <span class="o">=</span> <span class="o">-</span><span class="n">D</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reject_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">last</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reject_count</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">break</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span></div></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, PyPose Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
              <!-- <a class="twitter-timeline" data-width="15%" href="https://twitter.com/pypose_org?ref_src=twsrc%5Etfw">Tweets by pypose_org</a> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> -->
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
         <script src="../../../../_static/doctools.js"></script>
         <script src="../../../../_static/sphinx_highlight.js"></script>
         <script src="../../../../_static/katex.min.js"></script>
         <script src="../../../../_static/auto-render.min.js"></script>
         <script src="../../../../_static/katex_autorenderer.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Developer Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access documentation for PyPose</p>
          <a class="with-right-arrow" href="https://pypose.org/docs/main/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get started with tutorials and examples</p>
          <a class="with-right-arrow" href="https://pypose.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Get Started</h2>
          <p>Find resources and how to start using pypose</p>
          <a class="with-right-arrow" href="https://pypose.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pypose.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pypose.org/">Pypose</a></li>
            <li><a href="https://pypose.org/get-started">Get Started</a></li>
            <li><a href="https://pypose.org/features">Features</a></li>
            <li><a href="https://github.com/pypose/pypose/blob/main/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pypose.org/resources">Resources</a></li>
            <li><a href="https://pypose.org/tutorials">Tutorials</a></li>
            <li><a href="https://pypose.org/docs/main/index.html">Docs</a></li>
            <li><a href="https://github.com/pypose/pypose/issues" target="_blank">Github Issues</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://twitter.com/pypose_org" target="_blank">Twitter</a></li>
            <li><a href="https://github.com/pypose/pypose" target="_blank">GitHub</a></li>

          </ul>  
          </div>
        </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebooks Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pypose.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pypose.org/get-started">Get Started</a>
          </li>
          <li>
            <a href="https://pypose.org/tutorials">Tutorials</a>
          </li>
          <li>
            <a href="https://pypose.org/docs/main/index.html">Docs</a>
          </li>
          <li>
            <a href="https://pypose.org/about-us">About Us</a>
          </li>
          <li>
            <a href="https://github.com/pypose/pypose">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>