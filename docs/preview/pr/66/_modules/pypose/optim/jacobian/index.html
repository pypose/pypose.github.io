<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pypose.optim.jacobian &mdash; PyPose 0.0.1 documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/katex-math.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/contrib/auto-render.min.js"></script>
        <script src="../../../../_static/katex_autorenderer.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex/" />
    <link rel="search" title="Search" href="../../../../search/" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../" class="icon icon-home"> PyPose
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../lietensor/">LieTensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../basics/">Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../convert/">Convert</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules/">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim/">Optimization</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../">PyPose</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../">Module code</a> &raquo;</li>
      <li>pypose.optim.jacobian</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for pypose.optim.jacobian</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">functorch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">torch.autograd.functional</span> <span class="kn">import</span> <span class="n">jacobian</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Callable</span>


<span class="c1"># Utilities to make nn.Module &quot;functional&quot;</span>
<span class="c1"># In particular the goal is to be able to provide a function that takes as input</span>
<span class="c1"># the parameters and evaluate the nn.Module using fixed inputs.</span>
<span class="k">def</span> <span class="nf">_del_nested_attr</span><span class="p">(</span><span class="n">obj</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Deletes the attribute specified by the given list of names.</span>
<span class="sd">    For example, to delete the attribute obj.conv.weight,</span>
<span class="sd">    use _del_nested_attr(obj, [&#39;conv&#39;, &#39;weight&#39;])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">delattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">_del_nested_attr</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">names</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">names</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>


<span class="k">def</span> <span class="nf">_set_nested_attr</span><span class="p">(</span><span class="n">obj</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">value</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Set the attribute specified by the given list of names to value.</span>
<span class="sd">    For example, to set the attribute obj.conv.weight,</span>
<span class="sd">    use _del_nested_attr(obj, [&#39;conv&#39;, &#39;weight&#39;], value)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">names</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">_set_nested_attr</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">names</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">names</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">value</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">extract_weights</span><span class="p">(</span><span class="n">mod</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function removes all the Parameters from the model and</span>
<span class="sd">    return them as a tuple as well as their original attribute names.</span>
<span class="sd">    The weights must be re-loaded with `load_weights` before the model</span>
<span class="sd">    can be used again.</span>
<span class="sd">    Note that this function modifies the model in place and after this</span>
<span class="sd">    call, mod.parameters() will be empty.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">orig_params</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">mod</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
    <span class="c1"># Remove all the parameters in the model</span>
    <span class="n">names</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">mod</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()):</span>
        <span class="n">_del_nested_attr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">))</span>
        <span class="n">names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

    <span class="c1"># Make params regular Tensors instead of nn.Parameter</span>
    <span class="n">params</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">orig_params</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">names</span><span class="p">,</span> <span class="n">params</span>


<span class="k">def</span> <span class="nf">load_weights</span><span class="p">(</span><span class="n">mod</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">params</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Reload a set of weights so that `mod` can be used again to perform a forward pass.</span>
<span class="sd">    Note that the `params` are regular Tensors (that can have history) and so are left</span>
<span class="sd">    as Tensors. This means that mod.parameters() will still be empty after this call.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="n">_set_nested_attr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">),</span> <span class="n">p</span><span class="p">)</span>


<div class="viewcode-block" id="modjac"><a class="viewcode-back" href="../../../../generated/pypose.optim.modjac/#pypose.optim.modjac">[docs]</a><span class="k">def</span> <span class="nf">modjac</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">flatten</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">vectorize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;reverse-mode&#39;</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Compute the model Jacobian with respect to the model parameters.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (torch.nn.Module): a PyTorch model that takes Tensor inputs and</span>
<span class="sd">            returns a tuple of Tensors or a Tensor.</span>
<span class="sd">        inputs (tuple of Tensors or Tensor): inputs to the function ``func``.</span>
<span class="sd">        flatten (bool, optional): If ``True``, all module parameters are flattened</span>
<span class="sd">            and concatenated to form a single vector. The Jacobian will be computed</span>
<span class="sd">            with respect to this single flattened parameter.</span>
<span class="sd">        create_graph (bool, optional): If ``True``, the Jacobian will be</span>
<span class="sd">            computed in a differentiable manner. Note that when ``strict`` is</span>
<span class="sd">            ``False``, the result can not require gradients or be disconnected</span>
<span class="sd">            from the inputs.  Defaults to ``False``.</span>
<span class="sd">        strict (bool, optional): If ``True``, an error will be raised when we</span>
<span class="sd">            detect that there exists an input such that all the outputs are</span>
<span class="sd">            independent of it. If ``False``, we return a Tensor of zeros as the</span>
<span class="sd">            jacobian for said inputs, which is the expected mathematical value.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        vectorize (bool, optional): When computing the jacobian, usually we invoke</span>
<span class="sd">            ``autograd.grad`` once per row of the jacobian. If this flag is</span>
<span class="sd">            ``True``, we perform only a single ``autograd.grad`` call with</span>
<span class="sd">            ``batched_grad=True`` which uses the vmap prototype feature.</span>
<span class="sd">            Though this should lead to performance improvements in many cases,</span>
<span class="sd">            because this feature is still experimental, there may be performance</span>
<span class="sd">            cliffs. See :func:`torch.autograd.grad`&#39;s ``batched_grad`` parameter for</span>
<span class="sd">            more information.</span>
<span class="sd">        strategy (str, optional): Set to ``&quot;forward-mode&quot;`` or ``&quot;reverse-mode&quot;`` to</span>
<span class="sd">            determine whether the Jacobian will be computed with forward or reverse</span>
<span class="sd">            mode AD. Currently, ``&quot;forward-mode&quot;`` requires ``vectorized=True``.</span>
<span class="sd">            Defaults to ``&quot;reverse-mode&quot;``. If ``func`` has more outputs than</span>
<span class="sd">            inputs, ``&quot;forward-mode&quot;`` tends to be more performant. Otherwise,</span>
<span class="sd">            prefer to use ``&quot;reverse-mode&quot;``.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Jacobian (Tensor or nested tuple of Tensors): if there is a single</span>
<span class="sd">        output and ``flatten=True``, this will be a single Tensor containing the</span>
<span class="sd">        Jacobian for the linearized inputs and output. If either one doesn&#39;t</span>
<span class="sd">        hold, then the Jacobian will be a tuple of Tensors. If both of</span>
<span class="sd">        them don&#39;t hold, then the Jacobian will be a tuple of tuple of</span>
<span class="sd">        Tensors where ``Jacobian[i][j]`` will contain the Jacobian of the</span>
<span class="sd">        ``i``\th output and ``j``\th parameter and will have as size the</span>
<span class="sd">        concatenation of the sizes of the corresponding output and the</span>
<span class="sd">        corresponding parameter and will have same dtype and device as the</span>
<span class="sd">        corresponding input. If strategy is ``forward-mode``, the dtype will be</span>
<span class="sd">        that of the output; otherwise, the parameter.</span>

<span class="sd">    Warning:</span>
<span class="sd">        The function :obj:`modjac` calculate Jacobian of model parameters.</span>
<span class="sd">        This is in contrast to PyTorch&#39;s function `jacobian</span>
<span class="sd">        &lt;https://pytorch.org/docs/stable/generated/torch.autograd.functional.jacobian.html&gt;`_,</span>
<span class="sd">        which computes the Jacobian of a given Python function.</span>

<span class="sd">    Example:</span>

<span class="sd">        Calculates Jacobian with respect to all model parameters.</span>

<span class="sd">        &gt;&gt;&gt; model = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=1)</span>
<span class="sd">        &gt;&gt;&gt; inputs = torch.randn(1, 1, 1)</span>
<span class="sd">        &gt;&gt;&gt; J = pp.optim.modjac(model, inputs)</span>
<span class="sd">        (tensor([[[[[[[0.3365]]]]]]]), tensor([[[[1.]]]]))</span>
<span class="sd">        &gt;&gt;&gt; [j.shape for j in J]</span>
<span class="sd">        [torch.Size([1, 1, 1, 1, 1, 1, 1]), torch.Size([1, 1, 1, 1])]</span>

<span class="sd">        Function with flattened parameters returns a combined Jacobian.</span>

<span class="sd">        &gt;&gt;&gt; inputs = torch.randn(2, 2, 2)</span>
<span class="sd">        &gt;&gt;&gt; model = nn.Conv2d(in_channels=2, out_channels=2, kernel_size=1)</span>
<span class="sd">        &gt;&gt;&gt; J = pp.optim.modjac(model, inputs, flatten=True)</span>
<span class="sd">        tensor([[[[-1.1571, -1.6217,  0.0000,  0.0000,  1.0000,  0.0000],</span>
<span class="sd">                  [ 0.2917, -1.1545,  0.0000,  0.0000,  1.0000,  0.0000]],</span>
<span class="sd">                 [[-1.4052,  0.7642,  0.0000,  0.0000,  1.0000,  0.0000],</span>
<span class="sd">                  [ 0.7777, -1.5251,  0.0000,  0.0000,  1.0000,  0.0000]]],</span>
<span class="sd">                [[[ 0.0000,  0.0000, -1.1571, -1.6217,  0.0000,  1.0000],</span>
<span class="sd">                  [ 0.0000,  0.0000,  0.2917, -1.1545,  0.0000,  1.0000]],</span>
<span class="sd">                 [[ 0.0000,  0.0000, -1.4052,  0.7642,  0.0000,  1.0000],</span>
<span class="sd">                  [ 0.0000,  0.0000,  0.7777, -1.5251,  0.0000,  1.0000]]]])</span>
<span class="sd">        &gt;&gt;&gt; J.shape</span>
<span class="sd">        torch.Size([2, 2, 2, 6])</span>

<span class="sd">        Calculate Jacobian with respect to :obj:`pypose.LieTensor`.</span>

<span class="sd">        &gt;&gt;&gt; class PoseTransform(torch.nn.Module):</span>
<span class="sd">        ...     def __init__(self):</span>
<span class="sd">        ...         super().__init__()</span>
<span class="sd">        ...         self.p = pp.Parameter(pp.randn_so3(2))</span>
<span class="sd">        ...</span>
<span class="sd">        ...     def forward(self, x):</span>
<span class="sd">        ...         return self.p.Exp() * x</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; model, inputs = PoseTransform(), pp.randn_SO3()</span>
<span class="sd">        &gt;&gt;&gt; J = pp.optim.modjac(model, inputs, flatten=True)</span>
<span class="sd">        tensor([[[ 0.6769,  0.4854,  0.3703,  0.0000,  0.0000,  0.0000],</span>
<span class="sd">                 [-0.6020,  0.6618,  0.1506,  0.0000,  0.0000,  0.0000],</span>
<span class="sd">                 [-0.1017, -0.3866,  0.8824,  0.0000,  0.0000,  0.0000],</span>
<span class="sd">                 [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],</span>
<span class="sd">                [[ 0.0000,  0.0000,  0.0000,  0.9671,  0.1685, -0.1407],</span>
<span class="sd">                 [ 0.0000,  0.0000,  0.0000, -0.2092,  0.9203, -0.2629],</span>
<span class="sd">                 [ 0.0000,  0.0000,  0.0000,  0.0665,  0.2907,  0.9380],</span>
<span class="sd">                 [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]])</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">names</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">extract_weights</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="c1"># deparameterize weights</span>

    <span class="k">if</span> <span class="n">flatten</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">numels</span><span class="p">,</span> <span class="n">shapes</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="p">[(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">(),</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">params</span><span class="p">])</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">param_as_input</span><span class="p">(</span><span class="o">*</span><span class="n">params</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">flatten</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">params</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="o">*</span><span class="n">params</span><span class="p">,</span> <span class="n">numels</span><span class="p">)</span>
            <span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">shapes</span><span class="p">)]</span>
        <span class="n">load_weights</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">jacobian</span><span class="p">(</span><span class="n">param_as_input</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">create_graph</span><span class="p">,</span> <span class="n">strict</span><span class="p">,</span> <span class="n">vectorize</span><span class="p">,</span> <span class="n">strategy</span><span class="p">)</span></div>


<div class="viewcode-block" id="modjacrev"><a class="viewcode-back" href="../../../../generated/pypose.optim.modjacrev/#pypose.optim.modjacrev">[docs]</a><span class="k">def</span> <span class="nf">modjacrev</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">has_aux</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">func</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">functorch</span><span class="o">.</span><span class="n">make_functional</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">jacrev</span> <span class="o">=</span> <span class="n">functorch</span><span class="o">.</span><span class="n">jacrev</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="n">argnums</span><span class="p">,</span> <span class="n">has_aux</span><span class="o">=</span><span class="n">has_aux</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">jacrev</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span></div>


<div class="viewcode-block" id="modjacfwd"><a class="viewcode-back" href="../../../../generated/pypose.optim.modjacfwd/#pypose.optim.modjacfwd">[docs]</a><span class="k">def</span> <span class="nf">modjacfwd</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">has_aux</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">func</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">functorch</span><span class="o">.</span><span class="n">make_functional</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">jacfwd</span> <span class="o">=</span> <span class="n">functorch</span><span class="o">.</span><span class="n">jacfwd</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="n">argnums</span><span class="p">,</span> <span class="n">has_aux</span><span class="o">=</span><span class="n">has_aux</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">jacfwd</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, PyPose Contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>