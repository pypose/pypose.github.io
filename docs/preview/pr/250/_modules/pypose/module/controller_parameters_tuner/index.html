


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pypose.module.controller_parameters_tuner &mdash; PyPose main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/katex-math.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex/" />
    <link rel="search" title="Search" href="../../../../search/" />

<!--
  Search engines should not index the master version of documentation.
  Stable documentation are built without release == 'main'.
-->
<meta name="robots" content="noindex">


  <!-- Google Analytics -->
  
  <!-- End Google Analytics -->
  


  
  <script src="../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pypose.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pypose.org/get-started">Get Started</a>
          </li>

          <!-- <li> -->
          <li>
            <a href="https://pypose.org/tutorials">Tutorials</a>
          </li>

          <!-- <li class="active docs-active"> -->
          <li>
            <a href="https://pypose.org/docs/main/index.html">Doc</a>
          </li>

          <li>
            <a href="https://pypose.org/about-us">About Us</a>
          </li>

          <li>
            <a href="https://github.com/pypose/pypose">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pypose.org/docs/versions.html'>0.5.0 &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search/" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          

<div>
  <a style="color:#F05732" href="_modules/pypose/module/controller_parameters_tuner.html">
    You are viewing unstable developer preview docs.
    Click here to view docs for latest stable release.
  </a>
</div>


            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../lietensor/">LieTensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../func/">Func</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functions/">Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../convert/">Convert</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules/">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim/">Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../utils/">Utils</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../">Module code</a> &gt;</li>
        
      <li>pypose.module.controller_parameters_tuner</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for pypose.module.controller_parameters_tuner</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.autograd.functional</span> <span class="kn">import</span> <span class="n">jacobian</span>


<div class="viewcode-block" id="ControllerParametersTuner"><a class="viewcode-back" href="../../../../generated/pypose.module.ControllerParametersTuner/#pypose.module.ControllerParametersTuner">[docs]</a><span class="k">class</span> <span class="nc">ControllerParametersTuner</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">            learning_rate(float): gradient descent step size</span>
<span class="sd">            penalty_coefficient(float): controller-effort penalty coefficient</span>
<span class="sd">            device(string): on the cpu or cuda to perform the tuning process</span>

<span class="sd">    This class is the general implementation of the controller parameters tuner based on</span>
<span class="sd">    the sensitivity propagation.</span>

<span class="sd">    Given a dynamic system, the system state transition can be defined as</span>

<span class="sd">    .. math::</span>
<span class="sd">            \mathbf{x_{i+1}} = f(\mathbf{x_i}, \mathbf{u_i}) \tag{1}</span>

<span class="sd">    .. math::</span>
<span class="sd">            \mathbf{u_i} = h(\mathbf{x_i}, \mathbf{\hat{x_i}}, \pmb{\pmb{\theta}}) \tag{2}</span>

<span class="sd">    Where :math:`\mathbf{x_{i+1}}` stands for the dynmamic system states at time :math:`i+1`,</span>
<span class="sd">    :math:`\mathbf{x_i} \in \mathbb{R}^n` gives the dynamic system states at time :math:`i`,</span>
<span class="sd">    :math:`\mathbf{\hat x_i} \in \mathbb{R}^n` gives the system reference states at time :math:`i`,</span>
<span class="sd">    :math:`\mathbf{u_i} \in \mathbb{R}^m` is the controller-generated system inputs at time :math:`i`,</span>
<span class="sd">    :math:`\mathbf{\pmb{\theta}}` is the controller parameters.</span>

<span class="sd">    Note:</span>
<span class="sd">        For the parameter initial_state and parameters, please use 1d row vector to</span>
<span class="sd">        represent these variables at the same time.</span>



<span class="sd">    Given a dynamic system, a corresponding controller and reference states, assuming all</span>
<span class="sd">    these components are differentiable, it is possbile to find the most suitable</span>
<span class="sd">    parameters by constructing the loss function :math:`L` and computing the gradient of</span>
<span class="sd">    :math:`L` with respect to controller parameters.</span>



<span class="sd">    .. math::</span>
<span class="sd">            L = \sum_{i=1}^N ||\mathbf{x_i} - \mathbf{\hat x_i}||^2 + \sum_{i=0}^{N-1} \lambda|| \mathbf{u_i} ||^2 \tag{3}</span>

<span class="sd">    Where :math:`L` is the Loss function. Here it works as the control-effort penalty in the loss function. :math:`\lambda` is the</span>
<span class="sd">    penalty coefficient.</span>

<span class="sd">    And we can get the derivatives as following:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \begin{align*}</span>
<span class="sd">            \nabla L_{\pmb{\theta}} &amp;= \sum_{i=1}^N \frac{\partial L}{\partial \mathbf{x_i}} \frac{\partial \mathbf{x_i}}{\partial \pmb{\theta}} + \sum_{i=0}^{N-1} \frac{\partial L}{\partial \mathbf{u_i}} \frac{\partial \mathbf{u_i}}{\partial \pmb{\theta}} \\</span>
<span class="sd">            \frac{\partial \mathbf{x_{i+1}}}{\partial \pmb{\theta}} &amp;= (\frac{\partial \mathbf{x_{i+1}}}{\partial \mathbf{x_i}} + \frac{\partial \mathbf{x_{i+1}}}{\partial \mathbf{u_i}}\frac{\partial \mathbf{u_i}}{\partial \mathbf{x_i}})</span>
<span class="sd">            \frac{\partial \mathbf{x_i}}{\partial \pmb{\theta}}+\frac{\partial \mathbf{x_{i+1}}}{\partial \mathbf{u_i}}\frac{\partial \mathbf{u_i}}{\partial \pmb{\theta}} \\</span>
<span class="sd">            \frac{\partial \mathbf{u_i}}{\partial \pmb{\theta}} &amp;= \frac{\partial \mathbf{u_i}}{\partial \mathbf{x_i}} \frac{\partial \mathbf{x_i}}{\partial \pmb{\theta}} + \frac{\partial \mathbf{u_i}}{\partial \pmb{\theta}}</span>
<span class="sd">        \end{align*} \tag{4}</span>

<span class="sd">    To make sure the controller parameters can stay in the reasonable and safe sets, after updating the parameters, it&#39;s essential to project the new parameters into</span>
<span class="sd">    the feasiable set. And the parameters can be updated using the following equation:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \pmb{\theta} \leftarrow P_{\Theta}(\pmb{\theta} - \alpha\nabla_{\pmb{\theta}}L) \tag{5}</span>


<span class="sd">    The whole controller parameters tuning pipeline can be found here:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \begin{aligned}</span>
<span class="sd">            &amp;\rule{120mm}{0.4pt}                                                                        \\</span>
<span class="sd">            &amp;\textbf{input}: \text{Initial state }\mathbf{\bar x_0}, \text{initial controller parameters }\pmb{\theta}_0,</span>
<span class="sd">            \text{feasible set }\Theta, \text{horizon }N,                                               \\</span>
<span class="sd">            &amp;\hspace{12mm} \text{desired states }\mathbf{\hat{x}_{1:N}}, \text{step size }\alpha,</span>
<span class="sd">            \text{and termination condiction } C                                                        \\</span>

<span class="sd">            &amp;\rule{120mm}{0.4pt}                                                                        \\</span>
<span class="sd">            &amp;\textbf{Output} \: \text{Tuned parameter: } \pmb{\theta}^{\ast}                                  \\</span>
<span class="sd">            &amp;\hspace{5mm} \text{Initialize }\pmb{\theta} \leftarrow \pmb{\theta}_0                                  \\</span>
<span class="sd">            &amp;\hspace{5mm} \text{While }C \text{ is FALSE }\textbf{do}                                   \\</span>
<span class="sd">            &amp;\hspace{10mm} \text{Reset } \mathbf{x_0} \text{ to } \mathbf{\bar x_0}.                                       \\</span>
<span class="sd">            &amp;\hspace{10mm} \textbf{for } k \leftarrow 0 \text{ to } N \textbf{ do}                           \\</span>
<span class="sd">            &amp;\hspace{15mm} \text{Obtain } \mathbf{x_i} \text{ from system and compute } \mathbf{x_{i+1}} \text{ and } \mathbf{u_i} \text{ using equation (1) and (2)}  \\</span>
<span class="sd">            &amp;\hspace{15mm} \text{Update} \frac{\partial \mathbf{x_i}}{\partial \pmb{\theta}} \text{ and } \frac{\partial \mathbf{u_i}}{\partial \pmb{\theta}} \text{using equation (4)} \\</span>
<span class="sd">            &amp;\hspace{15mm} \text{Compute } \frac{\partial L}{\partial \mathbf{x_i}} \text{ and } \frac{\partial L}{\partial \mathbf{u_i}}. \\</span>
<span class="sd">            &amp;\hspace{15mm} \text{Store } \mathbf{x_i}, \mathbf{u_i}, \frac{\partial \mathbf{x_{i+1}}}{\partial \pmb{\theta}}, \frac{\partial \mathbf{u_i}}{\partial \pmb{\theta}}, \frac{\partial L}{\partial \mathbf{x_i}}\text{ and } \frac{\partial L}{\partial \mathbf{u_i}}\text{ in memory}. \\</span>
<span class="sd">            &amp;\hspace{10mm} \textbf{end for} \\</span>
<span class="sd">            &amp;\hspace{10mm} \text{Compute }\nabla L_{\pmb{\theta}} \text{ using equation (4) and update } \pmb{\theta} \text{with equation (5).} \\</span>
<span class="sd">            &amp;\hspace{5mm} \textbf{end while}                                                \\</span>
<span class="sd">            &amp;\rule{120mm}{0.4pt}                                                            \\[-1.ex]</span>
<span class="sd">            &amp;\bf{return} \:  \text{the tuned parameters }\pmb{\theta}^{\ast} \leftarrow \pmb{\theta}                                                    \\[-1.ex]</span>
<span class="sd">            &amp;\rule{120mm}{0.4pt}                                                            \\[-1.ex]</span>
<span class="sd">       \end{aligned}</span>


<span class="sd">    Note:</span>
<span class="sd">        This controller parameter tuning algorithm is developed based on the method proposed by this paper:</span>

<span class="sd">        * Cheng, Sheng, et al. `DiffTune: Auto-Tuning through Auto-Differentiation. &lt;https://arxiv.org/abs/2209.10021&gt;`_ arXiv preprint arXiv:2209.10021 (2022).</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">penalty_coefficient</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">penalty_coefficient</span> <span class="o">=</span> <span class="n">penalty_coefficient</span>

<div class="viewcode-block" id="ControllerParametersTuner.tune"><a class="viewcode-back" href="../../../../generated/pypose.module.ControllerParametersTuner/#pypose.module.ControllerParametersTuner.tune">[docs]</a>    <span class="k">def</span> <span class="nf">tune</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dynamic_system</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">,</span> <span class="n">ref_states</span><span class="p">,</span> <span class="n">controller</span><span class="p">,</span>
             <span class="n">parameters_bound</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">states_to_tune</span><span class="p">,</span> <span class="n">func_get_state_error</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            dynamic_system (pypose.module.dynamics): dynamics system</span>
<span class="sd">            initial_state (Tensor): 1d tensor representing the states of the dynamic system</span>
<span class="sd">            ref_states (object): these reference states are defined by the user and no need to be specific formation,</span>
<span class="sd">                but it has to be able to be used by the controller anf function func_get_state_error. In this function, we assume the first reference state</span>
<span class="sd">                should not be equal to the system initial state.</span>
<span class="sd">            controller (pypose.module.controller): Linear or nonlinear controller to control the dynamic system</span>
<span class="sd">            parameters (Tensor): 1d tensor represent the controller parameters</span>
<span class="sd">            parameters_bound (Tensor): This set gives the minimum and the maximum</span>
<span class="sd">                value the parameters can reach</span>
<span class="sd">            tau: time interval considered in system</span>
<span class="sd">            states_to_tune (Tensor): choose which state needs to be considered in the</span>
<span class="sd">                loss function, usually only position is chosen.</span>
<span class="sd">            func_get_state_error (function): function has two inputs: system state and</span>
<span class="sd">                ref state. The function needs to be provided by users considering system</span>
<span class="sd">                state and ref state are not always in the same formation or dimension.</span>

<span class="sd">        Return:</span>
<span class="sd">            list of :obj:`Tensor`: tuned controller parameters, original state loss and</span>
<span class="sd">            new state loss using tuned controller parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">states_to_tune</span> <span class="o">=</span> <span class="n">states_to_tune</span><span class="o">.</span><span class="n">double</span><span class="p">()</span>
        <span class="n">states</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">dxdparam_gradients</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">dukdparam_gradients</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">system_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="n">initial_state</span><span class="p">)</span>
        <span class="n">controller_parameters</span> <span class="o">=</span> <span class="n">controller</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="n">states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">system_state</span><span class="p">)</span>
        <span class="n">dxdparam_gradients</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">initial_state</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">controller_parameters</span><span class="p">)],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="o">.</span><span class="n">double</span><span class="p">())</span>

        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">ref_state</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ref_states</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
            <span class="n">controller_input</span> <span class="o">=</span> <span class="n">controller</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">system_state</span><span class="p">,</span> \
                                <span class="n">ref_state</span><span class="o">=</span><span class="n">ref_state</span><span class="p">,</span> <span class="n">feed_forward_quantity</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

            <span class="n">system_new_state</span> <span class="o">=</span> <span class="n">dynamic_system</span><span class="o">.</span><span class="n">state_transition</span><span class="p">(</span><span class="n">system_state</span><span class="p">,</span> <span class="n">controller_input</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span>

            <span class="c1"># calcuate the state derivative wrt. the parameters and the input derivative wrt. the parameters</span>
            <span class="n">dhdx_func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">state</span><span class="p">:</span> <span class="n">controller</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="p">,</span> \
                                        <span class="n">ref_state</span> <span class="o">=</span> <span class="n">ref_state</span><span class="p">,</span> <span class="n">feed_forward_quantity</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">dhdxk_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">jacobian</span><span class="p">(</span><span class="n">dhdx_func</span><span class="p">,</span> <span class="n">system_state</span><span class="p">))</span>

            <span class="c1"># dhdparam_func = lambda params: controller.forward(state = system_state, \</span>
            <span class="c1">#                             ref_state = ref_state, feed_forward_quantity = None)</span>
            <span class="c1"># dhdparam_tensor = torch.squeeze(jacobian(dhdparam_func, controller_parameters))</span>

            <span class="n">dhdparam_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">controller_input</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">controller</span><span class="o">.</span><span class="n">parameters</span><span class="p">))</span><span class="o">.</span><span class="n">double</span><span class="p">()</span>
            <span class="c1"># for i in range(0, len(controller_input)):</span>
            <span class="c1">#     dhdparam_tensor[i] = torch.autograd.grad(controller_input[i], \</span>
            <span class="c1">#             controller.parameters, retain_graph=True)[0]</span>
            <span class="c1"># system_state = system_state.detach()</span>
            <span class="n">controller</span><span class="o">.</span><span class="n">parameters</span> <span class="o">=</span> <span class="n">controller</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="c1"># controller.parameters.requires_grad=True</span>

            <span class="n">dfdxk_func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">system_state</span><span class="p">:</span> <span class="n">dynamic_system</span><span class="o">.</span><span class="n">state_transition</span><span class="p">(</span><span class="n">state</span> <span class="o">=</span> <span class="n">system_state</span><span class="p">,</span>
                                                            <span class="nb">input</span> <span class="o">=</span> <span class="n">controller_input</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">tau</span><span class="p">)</span>
            <span class="n">dfdxk_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">jacobian</span><span class="p">(</span><span class="n">dfdxk_func</span><span class="p">,</span> <span class="n">system_state</span><span class="p">))</span>

            <span class="n">dfduk_func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">dynamic_system</span><span class="o">.</span><span class="n">state_transition</span><span class="p">(</span><span class="n">state</span> <span class="o">=</span> <span class="n">system_state</span><span class="p">,</span>
                                                                        <span class="nb">input</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">tau</span><span class="p">)</span>
            <span class="n">dfduk_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">jacobian</span><span class="p">(</span><span class="n">dfduk_func</span><span class="p">,</span> <span class="n">controller_input</span><span class="p">))</span>

            <span class="n">states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">system_new_state</span><span class="p">)</span>
            <span class="n">inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">controller_input</span><span class="p">)</span>
            <span class="n">system_state</span> <span class="o">=</span> <span class="n">system_new_state</span>

            <span class="n">last_gradient</span> <span class="o">=</span> <span class="n">dxdparam_gradients</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="n">dxdparam_gradients</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">dfdxk_tensor</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">dfduk_tensor</span><span class="p">,</span> <span class="n">dhdxk_tensor</span><span class="p">),</span> <span class="n">last_gradient</span><span class="p">)</span> \
                <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">dfduk_tensor</span><span class="p">,</span> <span class="n">dhdparam_tensor</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="n">dukdparam_gradients</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">dhdxk_tensor</span><span class="p">,</span> <span class="n">last_gradient</span><span class="p">)</span> <span class="o">+</span> <span class="n">dhdparam_tensor</span>
            <span class="p">)</span>

        <span class="c1"># accumulate the gradients</span>
        <span class="n">gradient_sum</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">controller_parameters</span><span class="p">),</span> <span class="mi">1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">double</span><span class="p">()</span>
        <span class="c1"># error summation between system state and reference state</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">double</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">ref_state_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ref_states</span><span class="p">)):</span>
            <span class="n">state_error</span> <span class="o">=</span> <span class="n">func_get_state_error</span><span class="p">(</span><span class="n">states</span><span class="p">[</span><span class="n">ref_state_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> \
                                               <span class="n">ref_states</span><span class="p">[</span><span class="n">ref_state_index</span><span class="p">])</span>
            <span class="n">state_error</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">state_error</span><span class="p">)</span>
            <span class="n">state_error</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">state_error</span><span class="p">,</span> <span class="n">states_to_tune</span><span class="p">)</span>
            <span class="n">gradient_sum</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">state_error</span><span class="p">,</span> \
                                                 <span class="n">dxdparam_gradients</span><span class="p">[</span><span class="n">ref_state_index</span><span class="p">]))</span>
            <span class="n">gradient_sum</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalty_coefficient</span> \
                <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">ref_state_index</span><span class="p">]),</span> \
                                       <span class="n">dukdparam_gradients</span><span class="p">[</span><span class="n">ref_state_index</span><span class="p">]))</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">state_error</span><span class="p">)</span>

        <span class="n">gradient_sum</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="n">gradient_sum</span><span class="p">))</span>
        <span class="n">loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ref_states</span><span class="p">)</span>

        <span class="n">min_parameters</span> <span class="o">=</span> <span class="n">parameters_bound</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">max_parameters</span> <span class="o">=</span> <span class="n">parameters_bound</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">controller_parameters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">max_parameters</span><span class="p">,</span> \
            <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">min_parameters</span><span class="p">,</span> <span class="n">controller_parameters</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradient_sum</span><span class="p">))</span>

        <span class="c1"># compute the loss using new controller parameters</span>
        <span class="n">controller</span><span class="o">.</span><span class="n">parameters</span> <span class="o">=</span> <span class="n">controller_parameters</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="n">new_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_computation</span><span class="p">(</span><span class="n">dynamic_system</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">,</span> <span class="n">ref_states</span><span class="p">,</span> \
                    <span class="n">controller</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">states_to_tune</span><span class="p">,</span> <span class="n">func_get_state_error</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">controller_parameters</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">new_loss</span></div>

<div class="viewcode-block" id="ControllerParametersTuner.loss_computation"><a class="viewcode-back" href="../../../../generated/pypose.module.ControllerParametersTuner/#pypose.module.ControllerParametersTuner.loss_computation">[docs]</a>    <span class="k">def</span> <span class="nf">loss_computation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dynamic_system</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">,</span> <span class="n">ref_states</span><span class="p">,</span> <span class="n">controller</span><span class="p">,</span>
                         <span class="n">tau</span><span class="p">,</span> <span class="n">states_to_tune</span><span class="p">,</span> <span class="n">func_get_state_error</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the loss besed on the given controller parameters and state error defined</span>
<span class="sd">        by the func_get_state_error input parameter.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">system_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="n">initial_state</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">double</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">ref_state</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ref_states</span><span class="p">):</span>
            <span class="n">controller_input</span> <span class="o">=</span> <span class="n">controller</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">system_state</span><span class="p">,</span> \
                                    <span class="n">ref_state</span><span class="o">=</span><span class="n">ref_state</span><span class="p">,</span> <span class="n">feed_forward_quantity</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">system_new_state</span> <span class="o">=</span> <span class="n">dynamic_system</span><span class="o">.</span><span class="n">state_transition</span><span class="p">(</span><span class="n">system_state</span><span class="p">,</span> \
                                                               <span class="n">controller_input</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span>
            <span class="n">state_error</span> <span class="o">=</span> <span class="n">func_get_state_error</span><span class="p">(</span><span class="n">system_new_state</span><span class="p">,</span> <span class="n">ref_state</span><span class="p">)</span>
            <span class="n">state_error</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">state_error</span><span class="p">)</span>
            <span class="n">state_error</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">state_error</span><span class="p">,</span> <span class="n">states_to_tune</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">state_error</span><span class="p">)</span>

            <span class="n">system_state</span> <span class="o">=</span> <span class="n">system_new_state</span>
        <span class="n">loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ref_states</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span></div></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, PyPose Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <a class="twitter-timeline" data-chrome="noborders" href="https://twitter.com/pypose_org?ref_src=twsrc%5Etfw">Tweets by pypose_org<br>You need VPN if you see this.</a> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
         <script src="../../../../_static/jquery.js"></script>
         <script src="../../../../_static/underscore.js"></script>
         <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../../_static/doctools.js"></script>
         <script src="../../../../_static/katex.min.js"></script>
         <script src="../../../../_static/auto-render.min.js"></script>
         <script src="../../../../_static/katex_autorenderer.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Developer Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access documentation for PyPose</p>
          <a class="with-right-arrow" href="https://pypose.org/docs/main/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get started with tutorials and examples</p>
          <a class="with-right-arrow" href="https://pypose.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Get Started</h2>
          <p>Find resources and how to start using pypose</p>
          <a class="with-right-arrow" href="https://pypose.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pypose.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pypose.org/">Pypose</a></li>
            <li><a href="https://pypose.org/get-started">Get Started</a></li>
            <li><a href="https://pypose.org/features">Features</a></li>
            <li><a href="https://github.com/pypose/pypose/blob/main/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pypose.org/resources">Resources</a></li>
            <li><a href="https://pypose.org/tutorials">Tutorials</a></li>
            <li><a href="https://pypose.org/docs/main/index.html">Docs</a></li>
            <li><a href="https://github.com/pypose/pypose/issues" target="_blank">Github Issues</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://twitter.com/pypose_org" target="_blank">Twitter</a></li>
            <li><a href="https://github.com/pypose/pypose" target="_blank">GitHub</a></li>

          </ul>  
          </div>
        </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pypose.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pypose.org/get-started">Get Started</a>
          </li>
          <li>
            <a href="https://pypose.org/tutorials">Tutorials</a>
          </li>
          <li>
            <a href="https://pypose.org/docs/main/index.html">Docs</a>
          </li>
          <li>
            <a href="https://pypose.org/about-us">About Us</a>
          </li>
          <li>
            <a href="https://github.com/pypose/pypose">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>