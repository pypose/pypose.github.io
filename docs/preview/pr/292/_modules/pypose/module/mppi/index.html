


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pypose.module.mppi &mdash; PyPose main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/katex-math.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex/" />
    <link rel="search" title="Search" href="../../../../search/" />

<!--
  Search engines should not index the master version of documentation.
  Stable documentation are built without release == 'main'.
-->
<meta name="robots" content="noindex">


  <!-- Google Analytics -->
  
  <!-- End Google Analytics -->
  


  
  <script src="../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pypose.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pypose.org/get-started">Get Started</a>
          </li>

          <!-- <li> -->
          <li>
            <a href="https://pypose.org/tutorials">Tutorials</a>
          </li>

          <!-- <li class="active docs-active"> -->
          <li>
            <a href="https://pypose.org/docs/main/index.html">Doc</a>
          </li>

          <li>
            <a href="https://pypose.org/about-us">About Us</a>
          </li>

          <li>
            <a href="https://github.com/pypose/pypose">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pypose.org/docs/versions.html'>0.6.4 &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search/" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          

<div>
  <a style="color:#F05732" href="_modules/pypose/module/mppi.html">
    You are viewing unstable developer preview docs.
    Click here to view docs for latest stable release.
  </a>
</div>


            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../lietensor/">LieTensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../func/">Func</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functions/">Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../convert/">Convert</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules/">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim/">Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../utils/">Utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../testing/">Testing</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../">Module code</a> &gt;</li>
        
      <li>pypose.module.mppi</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for pypose.module.mppi</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="c1">#import numpy as np</span>
<span class="kn">from</span> <span class="nn">torch.distributions.multivariate_normal</span> <span class="kn">import</span> <span class="n">MultivariateNormal</span>

<span class="k">def</span> <span class="nf">_ensure_non_zero</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">factor</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">factor</span> <span class="o">*</span> <span class="p">(</span><span class="n">cost</span> <span class="o">-</span> <span class="n">beta</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">is_tensor_like</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1">#or type(x) is np.ndarray</span>


<span class="k">def</span> <span class="nf">squeeze_n</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">n_squeeze</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_squeeze</span><span class="p">):</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">v</span>


<span class="c1"># from arm_pytorch_utilities, standalone since that package is not on pypi yet</span>
<span class="k">def</span> <span class="nf">handle_batch_input</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_handle_batch_input</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;For func that expect 2D input, handle input that have more than 2 dimensions by</span>
<span class="sd">        flattening them temporarily&quot;&quot;&quot;</span>

        <span class="nd">@functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="c1"># assume inputs that are tensor-like have compatible shapes and is represented</span>
            <span class="c1"># by the first argument</span>
            <span class="n">batch_dims</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">is_tensor_like</span><span class="p">(</span><span class="n">arg</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">arg</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">n</span><span class="p">:</span>
                        <span class="c1"># last dimension is type dependent; all previous ones are batches</span>
                        <span class="n">batch_dims</span> <span class="o">=</span> <span class="n">arg</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
                        <span class="k">break</span>
                    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">arg</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">:</span>
                        <span class="n">n_batch_dims_to_add</span> <span class="o">=</span> <span class="n">n</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">arg</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                        <span class="n">batch_ones_to_add</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_batch_dims_to_add</span>
                        <span class="n">args</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">batch_ones_to_add</span><span class="p">,</span> <span class="o">*</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">is_tensor_like</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>\
                            <span class="k">else</span> <span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">args</span><span class="p">]</span>
                        <span class="n">ret</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ret</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                            <span class="n">ret</span> <span class="o">=</span> <span class="p">[</span><span class="n">squeeze_n</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">n_batch_dims_to_add</span><span class="p">)</span> <span class="k">if</span> <span class="n">is_tensor_like</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>\
                                <span class="k">else</span> <span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">ret</span><span class="p">]</span>
                            <span class="k">return</span> <span class="n">ret</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">is_tensor_like</span><span class="p">(</span><span class="n">ret</span><span class="p">):</span>
                                <span class="k">return</span> <span class="n">squeeze_n</span><span class="p">(</span><span class="n">ret</span><span class="p">,</span> <span class="n">n_batch_dims_to_add</span><span class="p">)</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="k">return</span> <span class="n">ret</span>
            <span class="c1"># no batches; just return normally</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">batch_dims</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="c1"># reduce all batch dimensions down to the first one</span>
            <span class="n">args</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):])</span> <span class="k">if</span> <span class="p">(</span><span class="n">is_tensor_like</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="ow">and</span> \
                <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">)</span> <span class="k">else</span> <span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">args</span><span class="p">]</span>
            <span class="n">ret</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="c1"># restore original batch dimensions; keep variable dimension (nx)</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">tuple</span><span class="p">:</span>
                <span class="n">ret</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span> <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">is_tensor_like</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span>
                    <span class="n">v</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">batch_dims</span><span class="p">,</span> <span class="o">*</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):])</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span> \
                        <span class="k">else</span> <span class="n">v</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">ret</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">is_tensor_like</span><span class="p">(</span><span class="n">ret</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ret</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
                        <span class="n">ret</span> <span class="o">=</span> <span class="n">ret</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">batch_dims</span><span class="p">,</span> <span class="o">*</span><span class="n">ret</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):])</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">ret</span> <span class="o">=</span> <span class="n">ret</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">batch_dims</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">ret</span>

        <span class="k">return</span> <span class="n">wrapper</span>

    <span class="k">return</span> <span class="n">_handle_batch_input</span>


<div class="viewcode-block" id="MPPI"><a class="viewcode-back" href="../../../../generated/pypose.module.MPPI/#pypose.module.MPPI">[docs]</a><span class="k">class</span> <span class="nc">MPPI</span><span class="p">():</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Model Predictive Path Integral (MPPI) control.</span>
<span class="sd">    This implementation batch samples the trajectories and scales well with the number of</span>
<span class="sd">    samples :math:`K`.</span>

<span class="sd">    Args:</span>
<span class="sd">        dynamics (callable): Function(state, action) -&gt; next_state. The dynamics model</span>
<span class="sd">            of the system.</span>
<span class="sd">        running_cost (callable): Function to compute the cost associated with a given</span>
<span class="sd">            state and action.</span>
<span class="sd">        nx (int): Dimension of the state.</span>
<span class="sd">        noise_sigma (Tensor): Control noise covariance.</span>
<span class="sd">        num_samples (int): Number of trajectories to sample.</span>
<span class="sd">        horizon (int): Length of each trajectory.</span>
<span class="sd">        device (str): PyTorch device.</span>
<span class="sd">        noise_mu (Tensor, optional): Mean for the control noise distribution. Defaults to</span>
<span class="sd">            a tensor of zeros.</span>
<span class="sd">        lambda_ (float, optional): Temperature parameter that weighs the importance of</span>
<span class="sd">            the cost relative to the control noise. Higher values lead to more exploration.</span>
<span class="sd">        u_min (Tensor, optional): Minimum boundary for the control action. Defaults to</span>
<span class="sd">            negative infinity.</span>
<span class="sd">        u_max (Tensor, optional): Maximum boundary for the control action. Defaults to</span>
<span class="sd">            positive infinity.</span>
<span class="sd">        noise_abs_cost (float, optional): Absolute cost associated with the noise. Helps</span>
<span class="sd">            in weighing the magnitude of noise added to the control. Defaults to zero.</span>

<span class="sd">    MPPI is a variant of NMPC that repeatedly solves finite-horizon optimal control tasks</span>
<span class="sd">    while utilizing nonlinear dynamics and general cost functions, which can be</span>
<span class="sd">    nonquadratic and even discontinuous. Specifically, it samples thousands</span>
<span class="sd">    of trajectories around some mean control sequence in real-time by taking advantage of</span>
<span class="sd">    the parallel computing capabilities of modern Graphic Processing Units(GPUs), then</span>
<span class="sd">    produces an optimal trajectory along with its corresponding control sequence by</span>
<span class="sd">    calculating the weighted average of the cost of all samples</span>

<span class="sd">    Given current state :math:`X`, control signal :math:`U`, and</span>
<span class="sd">    predicting horizon :math:`N`.At each timestep, the MPPI controller aims to solve:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \begin{align*}</span>
<span class="sd">            \min_{\mathbf{U}} J (\mathbf{U}) &amp;= \mathbb{E} \left[ \sum_{k=0}^{N-1}</span>
<span class="sd">                \left(q_k(\mathbf{x}_k, \mathbf{u}_k) +</span>
<span class="sd">                \frac{1}{2}\mathbf{u}_k^\top\mathbf{R}\mathbf{u}_k\right) +</span>
<span class="sd">                \phi(\mathbf{x}_N)\right] \\</span>
<span class="sd">            \text{subject to} \quad</span>
<span class="sd">            &amp;\mathbf{x}_{k+1} = F(\mathbf{x}_k, \mathbf{u}_k + \bm{\epsilon}_k) \\</span>
<span class="sd">            &amp;\mathbf{X}(0) = \mathbf{x}_0, \quad \bm{\epsilon}_k \sim</span>
<span class="sd">                \mathcal{N} (0, \bm{\Sigma}_{\epsilon})</span>
<span class="sd">        \end{align*}</span>

<span class="sd">    where :math:`J` is the objective function, :math:`\mathbb{E}` is the expected value</span>
<span class="sd">    , :math:`q_k` is the stage cost, :math:`\phi` is the terminal cost, :math:`F` is</span>
<span class="sd">    denotes the system&#39;s dynamics which comprises of hexarotor and contact dynamics,</span>
<span class="sd">    and :math:`\epsilon` represents a sampled noise or perturbation added to the control</span>
<span class="sd">    sequence at time step :math:`k`, which is modeled by Ornstein-Uhlenbeck process. Under</span>
<span class="sd">    this definition, the objective is to minimize the expectation of the state and control</span>
<span class="sd">    costs with a random state vector while satisfying the dynamics constraints.</span>

<span class="sd">    The MPPI algorithm samples :math:`M` trajectories at each time horizon. Let us denote</span>
<span class="sd">    :math:`\mathbf{U}&#39; = \begin{bmatrix} \mathbf{u}_0&#39; &amp; \mathbf{u}_1&#39;</span>
<span class="sd">    &amp; \cdots &amp; \mathbf{u}_{N-1}&#39;\end{bmatrix}` as the nominal/mean control sequence,</span>
<span class="sd">    :math:`\bm{E}^{(j)} = \begin{bmatrix} \bm{\epsilon}_0^{(j)}</span>
<span class="sd">    &amp; \bm{\epsilon}_1^{(j)} &amp; \cdots &amp; \bm{\epsilon}_{N-1}^{(j)}\end{bmatrix}`,</span>
<span class="sd">    where :math:`\bm{\epsilon}_k^{(j)} \sim  \mathcal{N}(0, \bm{\Sigma}_{\epsilon})`</span>
<span class="sd">    as the control disturbance sequence of the :math:`j^{\mathrm{th}}` sampled trajectory,</span>
<span class="sd">    and :math:`\mathbf{U}^{(j)} = \begin{bmatrix} \mathbf{u}_0^{(j)} &amp; \mathbf{u}_1^{(j)}</span>
<span class="sd">    &amp; \cdots &amp; \mathbf{u}_{N-1}^{(j)}\end{bmatrix}` as the actual control sequence, such</span>
<span class="sd">    that :math:`\mathbf{U}^{(j)} = \mathbf{U}&#39; + \bm{E}^{j}`,</span>
<span class="sd">    where :math:`j = \begin{bmatrix} 1 &amp; \cdots &amp; M\end{bmatrix}`.</span>
<span class="sd">    The cost of the :math:`j^{\mathrm{th}}` sampled trajectory :math:`S_j` can be computed</span>
<span class="sd">    based on previous optimization problem.</span>
<span class="sd">    Then, the MPPI generates the optimal control sequence as well as the mean sequence for</span>
<span class="sd">    the next iteration by a weighted sum,</span>

<span class="sd">    .. math::</span>
<span class="sd">        \begin{equation*}</span>
<span class="sd">            \mathbf{U} = \sum_{j = 1}^M w_j\mathbf{U}^{(j)}/\sum_{j = 1}^{M} w_j</span>
<span class="sd">        \end{equation*}</span>

<span class="sd">    where the weights :math:`w_j` of the :math:`j^{\mathrm{th}}` sample is computed as:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \begin{equation*}</span>
<span class="sd">            w_j = \exp\left(-\frac{1}{\lambda}(S_j - \beta)\right)</span>
<span class="sd">        \end{equation*}</span>


<span class="sd">    to optimize the information-theoretical cost, where :math:`\beta =</span>
<span class="sd">    \min_{j=1,\cdots, M} S_j`, and :math:`\lambda` determines how selective is</span>
<span class="sd">    the weighted average.</span>

<span class="sd">    Note:</span>
<span class="sd">        The MPPI approach is based on the algorithm from Williams et al., 2017:</span>
<span class="sd">        &#39;Information Theoretic MPC for Model-Based Reinforcement Learning&#39;.</span>
<span class="sd">        The implementation is adapted from:</span>
<span class="sd">        https://github.com/UM-ARM-Lab/pytorch_mppi</span>
<span class="sd">        and https://github.com/ferreirafabio/mppi_pendulum.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; import pypose as pp</span>
<span class="sd">        &gt;&gt;&gt; class Simple2DNav(pp.module.System):</span>
<span class="sd">        ...     def __init__(self,dt,length=1.0):</span>
<span class="sd">        ...         super().__init__()</span>
<span class="sd">        ...         self._tau = dt</span>
<span class="sd">        ...         self._length=length</span>
<span class="sd">        ...</span>
<span class="sd">        ...     def state_transition(self, state, input, t=None):</span>
<span class="sd">        ...         x, y, theta = state.moveaxis(-1, 0)</span>
<span class="sd">        ...         v, omega = input.squeeze().moveaxis(-1, 0)</span>
<span class="sd">        ...         xDot = v * torch.cos(theta)</span>
<span class="sd">        ...         yDot = v * torch.sin(theta)</span>
<span class="sd">        ...         thetaDot = omega</span>
<span class="sd">        ...         _dstate = torch.stack((xDot, yDot, thetaDot), dim=-1)</span>
<span class="sd">        ...         return (state.squeeze() + torch.mul(_dstate, self._tau)).unsqueeze(0)</span>
<span class="sd">        ...</span>
<span class="sd">        ...     def observation(self, state, input, t=None):</span>
<span class="sd">        ...         return state</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; torch.manual_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; x0 = torch.tensor([0., 0., 0.], requires_grad=False)</span>
<span class="sd">        &gt;&gt;&gt; dt = 0.1</span>
<span class="sd">        &gt;&gt;&gt; cost_fn = lambda x, u, t: (x[..., 0] - 10)**2 + (x[..., 1] - 10)**2 \</span>
<span class="sd">        &gt;&gt;&gt; + (u[..., 0])**2</span>
<span class="sd">        &gt;&gt;&gt; mppi = MPPI(</span>
<span class="sd">        &gt;&gt;&gt;     dynamics=Simple2DNav(dt),</span>
<span class="sd">        &gt;&gt;&gt;     running_cost=cost_fn,</span>
<span class="sd">        &gt;&gt;&gt;     nx=3,</span>
<span class="sd">        &gt;&gt;&gt;     noise_sigma=torch.eye(2) * 1,</span>
<span class="sd">        &gt;&gt;&gt;     num_samples=100,</span>
<span class="sd">        &gt;&gt;&gt;     horizon=5,</span>
<span class="sd">        &gt;&gt;&gt;     lambda_=0.01</span>
<span class="sd">        &gt;&gt;&gt;     )</span>
<span class="sd">        &gt;&gt;&gt; u, xn= pp.mppi.forward(x0)</span>
<span class="sd">        &gt;&gt;&gt; print(&#39;u = &#39;, u)</span>
<span class="sd">        &gt;&gt;&gt; print(&#39;x = &#39;, xn)</span>
<span class="sd">        u =  tensor([[-1.0977,  0.6999],</span>
<span class="sd">                     [ 0.4890, -0.6172],</span>
<span class="sd">                     [ 1.3908, -0.6498],</span>
<span class="sd">                     [-0.1326, -0.2450],</span>
<span class="sd">                     [ 0.6668, -0.9944]])</span>
<span class="sd">        x =  tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],</span>
<span class="sd">                     [-1.0977e-01,  0.0000e+00,  6.9991e-02],</span>
<span class="sd">                     [-6.0990e-02,  3.4199e-03,  8.2744e-03],</span>
<span class="sd">                     [ 7.8084e-02,  4.5706e-03, -5.6704e-02],</span>
<span class="sd">                     [ 6.4848e-02,  5.3220e-03, -8.1209e-02],</span>
<span class="sd">                     [ 1.3131e-01, -8.6915e-05, -1.8065e-01]])</span>

<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">dynamics</span><span class="p">,</span>
                 <span class="n">running_cost</span><span class="p">,</span>
                 <span class="n">nx</span><span class="p">,</span>
                 <span class="n">noise_sigma</span><span class="p">,</span>
                 <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                 <span class="n">horizon</span><span class="o">=</span><span class="mf">15.0</span><span class="p">,</span>
                 <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
                 <span class="n">lambda_</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>
                 <span class="n">noise_mu</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">u_min</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">u_max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">noise_abs_cost</span><span class="o">=</span><span class="kc">False</span>
                 <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">noise_sigma</span><span class="o">.</span><span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">=</span> <span class="n">num_samples</span>  <span class="c1"># N_SAMPLES</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span class="n">horizon</span>  <span class="c1"># TIMESTEPS</span>
        <span class="c1"># dimensions of state and control</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nx</span> <span class="o">=</span> <span class="n">nx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nu</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">noise_sigma</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">noise_sigma</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span> <span class="o">=</span> <span class="n">lambda_</span>
        <span class="k">if</span> <span class="n">noise_mu</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">noise_mu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nu</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="c1"># handle 1D edge case</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nu</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">noise_mu</span> <span class="o">=</span> <span class="n">noise_mu</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">noise_sigma</span> <span class="o">=</span> <span class="n">noise_sigma</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># bounds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">u_min</span> <span class="o">=</span> <span class="n">u_min</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">u_max</span> <span class="o">=</span> <span class="n">u_max</span>
        <span class="c1"># make sure if any of them is specified, both are specified</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_max</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_min</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">u_max</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">u_max</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">u_max</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">u_min</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">u_max</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_min</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_max</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">u_min</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">u_min</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">u_min</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">u_max</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">u_min</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_min</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">u_min</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_min</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">u_max</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_max</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_mu</span> <span class="o">=</span> <span class="n">noise_mu</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_sigma</span> <span class="o">=</span> <span class="n">noise_sigma</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_sigma_inv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">noise_sigma</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_dist</span> <span class="o">=</span> <span class="n">MultivariateNormal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">noise_mu</span><span class="p">,</span> \
            <span class="n">covariance_matrix</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">noise_sigma</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">system</span> <span class="o">=</span> <span class="n">dynamics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">running_cost</span> <span class="o">=</span> <span class="n">running_cost</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_abs_cost</span> <span class="o">=</span> <span class="n">noise_abs_cost</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># sampled results from last command</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cost_total</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cost_total_non_zero</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">omega</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">states</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@handle_batch_input</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_dynamics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">u</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">u</span><span class="p">)</span> <span class="c1">#if self.step_dependency else self.system(state, u)</span>

    <span class="nd">@handle_batch_input</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_running_cost</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">running_cost</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

<div class="viewcode-block" id="MPPI.forward"><a class="viewcode-back" href="../../../../generated/pypose.module.MPPI/#pypose.module.MPPI.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">u_init</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Perform MPPI for discrete system</span>

<span class="sd">        Args:</span>
<span class="sd">            state (:obj:`Tensor`): The initial state of the system.</span>
<span class="sd">            u_init (:obj:`Tensor`, optinal): The current inputs of the system along a</span>
<span class="sd">                trajectory. Default: ``None``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of :obj:`Tensor`: A list of tensors including the solved input</span>
<span class="sd">            sequence :math:`\mathbf{u}` and the solved state sequence :math:`\mathbf{x}`</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c1"># shift command 1 time step</span>
        <span class="k">if</span> <span class="n">u_init</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">u_init</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">noise_mu</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">u_init</span> <span class="o">=</span> <span class="n">u_init</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">U</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_dist</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">,))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">U</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">U</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">U</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_init</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">)</span>
        <span class="n">cost_total</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_total_cost_batch</span><span class="p">()</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">cost_total</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cost_total_non_zero</span> <span class="o">=</span> <span class="n">_ensure_non_zero</span><span class="p">(</span><span class="n">cost_total</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">)</span>
        <span class="n">eta</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_total_non_zero</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">omega</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">eta</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_total_non_zero</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">U</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">U</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> \
                <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">omega</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span><span class="p">[:,</span> <span class="n">t</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">U</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">]</span>
        <span class="n">action2states</span><span class="o">=</span><span class="n">state</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">):</span>
            <span class="n">cur_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="n">action2states</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">action</span><span class="p">[</span><span class="n">i</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">action2states</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">action2states</span><span class="p">,</span><span class="n">cur_state</span><span class="p">),</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">action</span><span class="p">,</span> <span class="n">action2states</span></div>

    <span class="k">def</span> <span class="nf">_compute_rollout_costs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">perturbed_actions</span><span class="p">):</span>
        <span class="n">K</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">nu</span> <span class="o">=</span> <span class="n">perturbed_actions</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">assert</span> <span class="n">nu</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">nu</span>
        <span class="n">cost_total</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="c1">#cost_samples = cost_total.repeat(self.M, 1)</span>
        <span class="n">cost_samples</span> <span class="o">=</span> <span class="n">cost_total</span>
        <span class="c1"># allow propagation of a sample of states (ex. to carry a distribution),</span>
        <span class="c1"># or to start with a single state</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span><span class="p">):</span>
            <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">states</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">perturbed_actions</span><span class="p">[:,</span> <span class="n">t</span><span class="p">]</span>
            <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dynamics</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">u</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_running_cost</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
            <span class="n">cost_samples</span> <span class="o">=</span> <span class="n">cost_samples</span> <span class="o">+</span> <span class="n">c</span>
            <span class="n">states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
            <span class="n">actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="c1"># Actions is K x T x nu</span>
        <span class="c1"># States is K x T x nx</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">states</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">cost_total</span> <span class="o">=</span> <span class="n">cost_total</span> <span class="o">+</span> <span class="n">cost_samples</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">cost_total</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">actions</span>

    <span class="k">def</span> <span class="nf">_compute_total_cost_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># parallelize sampling across trajectories</span>
        <span class="c1"># resample noise each time we take an action</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_dist</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
        <span class="c1"># broadcast own control to noise over samples; now it&#39;s K x T x nu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">perturbed_action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">U</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span>
        <span class="c1"># naively bound control</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">perturbed_action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bound_action</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">perturbed_action</span><span class="p">)</span>
        <span class="c1"># bounded noise after bounding (some got cut off,</span>
        <span class="c1"># so we don&#39;t penalize that in action cost)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">perturbed_action</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">U</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_abs_cost</span><span class="p">:</span>
            <span class="n">action_cost</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">noise</span><span class="p">)</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_sigma_inv</span>
            <span class="c1"># NOTE: The original paper does</span>
            <span class="c1"># self.lambda_ * torch.abs(self.noise) @ self.noise_sigma_inv,</span>
            <span class="c1"># but this biases the actions with low noise if all states have the same cost.</span>
            <span class="c1"># With abs(noise) we prefer actions close to the nomial trajectory.</span>
        <span class="k">else</span><span class="p">:</span><span class="c1"># Like original paper</span>
            <span class="n">action_cost</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_sigma_inv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cost_total</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span> <span class="o">=</span>\
            <span class="bp">self</span><span class="o">.</span><span class="n">_compute_rollout_costs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">perturbed_action</span><span class="p">)</span>
        <span class="c1"># action perturbation cost</span>
        <span class="n">perturbation_cost</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">U</span> <span class="o">*</span> <span class="n">action_cost</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cost_total</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_total</span> <span class="o">+</span> <span class="n">perturbation_cost</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_total</span>

    <span class="k">def</span> <span class="nf">_bound_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_max</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">):</span>
                <span class="n">u</span> <span class="o">=</span> <span class="n">action</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slice_control</span><span class="p">(</span><span class="n">t</span><span class="p">)]</span>
                <span class="n">cu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_max</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_min</span><span class="p">)</span>
                <span class="n">action</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slice_control</span><span class="p">(</span><span class="n">t</span><span class="p">)]</span> <span class="o">=</span> <span class="n">cu</span>
        <span class="k">return</span> <span class="n">action</span>

    <span class="k">def</span> <span class="nf">_slice_control</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">slice</span><span class="p">(</span><span class="n">t</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">nu</span><span class="p">,</span> <span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">nu</span><span class="p">)</span></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, PyPose Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <a class="twitter-timeline" data-chrome="noborders" href="https://twitter.com/pypose_org?ref_src=twsrc%5Etfw">Tweets by pypose_org<br>You need VPN if you see this.</a> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
         <script src="../../../../_static/jquery.js"></script>
         <script src="../../../../_static/underscore.js"></script>
         <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../../_static/doctools.js"></script>
         <script src="../../../../_static/katex.min.js"></script>
         <script src="../../../../_static/auto-render.min.js"></script>
         <script src="../../../../_static/katex_autorenderer.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Developer Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access documentation for PyPose</p>
          <a class="with-right-arrow" href="https://pypose.org/docs/main/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get started with tutorials and examples</p>
          <a class="with-right-arrow" href="https://pypose.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Get Started</h2>
          <p>Find resources and how to start using pypose</p>
          <a class="with-right-arrow" href="https://pypose.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pypose.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pypose.org/">Pypose</a></li>
            <li><a href="https://pypose.org/get-started">Get Started</a></li>
            <li><a href="https://pypose.org/features">Features</a></li>
            <li><a href="https://github.com/pypose/pypose/blob/main/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pypose.org/resources">Resources</a></li>
            <li><a href="https://pypose.org/tutorials">Tutorials</a></li>
            <li><a href="https://pypose.org/docs/main/index.html">Docs</a></li>
            <li><a href="https://github.com/pypose/pypose/issues" target="_blank">Github Issues</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://twitter.com/pypose_org" target="_blank">Twitter</a></li>
            <li><a href="https://github.com/pypose/pypose" target="_blank">GitHub</a></li>

          </ul>  
          </div>
        </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebooks Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pypose.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pypose.org/get-started">Get Started</a>
          </li>
          <li>
            <a href="https://pypose.org/tutorials">Tutorials</a>
          </li>
          <li>
            <a href="https://pypose.org/docs/main/index.html">Docs</a>
          </li>
          <li>
            <a href="https://pypose.org/about-us">About Us</a>
          </li>
          <li>
            <a href="https://github.com/pypose/pypose">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>